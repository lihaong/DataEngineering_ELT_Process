# ğŸš€ ELT Pipeline: PostgreSQL and dbt Integration

## ğŸŒŸ Overview
This repository showcases a robust ELT (Extract, Load, Transform) pipeline designed to streamline your data workflows. Whether youâ€™re managing raw datasets or preparing analytics-ready tables, this pipeline has you covered! 

### Key Highlights:
1. **Extract**: Pull raw data from a **source PostgreSQL** database.
2. **Load**: Store the data in a structured format in a **destination PostgreSQL** database.
3. **Transform**: Use the power of [dbt](https://www.getdbt.com/) to apply modular, reusable SQL transformations.

ğŸ’¡ Orchestrated with **Apache Airflow** and deployed in a **Dockerized environment**, this pipeline ensures simplicity, scalability, and repeatability.

---

## âœ¨ Features
- ğŸ”„ **Automated Extract and Load**: Extract raw data and seamlessly load it into your destination database.
- ğŸ”§ **Effortless Transformation**: Use dbt to create, test, and version SQL models.
- âš™ï¸ **Orchestration at Scale**: Manage complex workflows with Apache Airflow.
- ğŸ‹ **Containerized Ecosystem**: All services run in isolated, self-contained Docker containers.
- ğŸŒ **Customizable**: Flexible enough to adapt to diverse datasets and workflows.

---

## ğŸ› ï¸ Architecture
**Visual Overview**:
```plaintext
   +----------------+            +-----------------------+           
   | Source         |            | Destination           |           
   | PostgreSQL     |  --->      | PostgreSQL            |           
   +----------------+            +-----------------------+           
           |                               ^
           |                               |                    
    Extract & Load                Transform (dbt)                    
           |                               |                    
       Airflow Orchestration                
```

---

## ğŸš€ Getting Started

### Prerequisites
- ğŸ³ Docker & Docker Compose installed.
- ğŸ”— Basic knowledge of PostgreSQL, dbt, and Airflow.

### Installation
1. Clone the repository:
   ```bash
   git clone https://github.com/lihaong/MobileApp_Ngojek.git
   cd MobileApp_Ngojek
   ```
2. Start the services:
   ```bash
   docker-compose up --build
   ```
3. Access Airflow:
   - ğŸŒ URL: [http://localhost:8080](http://localhost:8080)
   - ğŸ”‘ Username: `admin`
   - ğŸ”‘ Password: `admin`

---

## ğŸŒ€ Workflow

### Extract and Load
Python scripts automate data extraction from the source PostgreSQL and load it into the destination PostgreSQL database.

### Transform
- Create **reusable SQL models** using dbt.
- Execute transformations to produce analytics-ready datasets.

### Orchestrate
Airflow DAGs manage the pipeline and ensure tasks run efficiently.

---

## ğŸ“‚ Project Structure
```plaintext
.
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/               # Airflow DAGs
â”‚   â”œâ”€â”€ plugins/            # Custom Airflow plugins
â”œâ”€â”€ custom_postgres/         # dbt models and profiles
â”œâ”€â”€ elt_script/              # Python scripts for Extract and Load
â”œâ”€â”€ docker-compose.yml       # Docker Compose configuration
â””â”€â”€ README.md                # Project documentation
```

---

## ğŸŒˆ Customization
- **Extract and Load**: Update `elt_script` for different data sources or schemas.
- **Transform**: Modify dbt models in `custom_postgres/` to fit your needs.
- **Orchestrate**: Extend Airflow DAGs with additional tasks or dependencies.

---

## ğŸ¤ Contributions
We welcome contributions from the community!  
Submit your ideas, enhancements, or bug fixes through issues or pull requests.

---

## ğŸ“§ Contact
ğŸ“Œ Created by **Muhammad Fajar Andikha**  
ğŸ“¬ Reach out at: [your-email@example.com](mailto:your-email@example.com)

---

## ğŸ“ License
This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

---

ğŸŒŸ Happy ELT-ing! ğŸš€
```

This version adds icons, better formatting, and a lively tone to make your project more inviting and easier to navigate. Let me know if you'd like further tweaks!
